# DocQA 🤖
![image](https://github.com/afaqueumer/DocQA/assets/98417654/971c5d0f-3863-4d2b-858b-6f97e85e0f9d)

DocQA 🤖 is a web application built using Streamlit 🔥 and the LangChain 🦜🔗 framework, allowing users to leverage the power of LLMs for Generative Question Answering. 🌟

Read More Here 👉
https://ai.plainenglish.io/️-langchain-streamlit-llama-bringing-conversational-ai-to-your-local-machine-a1736252b172

## Installation
To run the LangChain web application locally, follow these steps:

Clone this repository 🔗
```
git clone https://github.com/afaqueumer/DocQA.git
```
Create Virtual Environment and Install the required dependencies ⚙️
```
Run ➡️ setup_env.bat 
```
Launch Streamlit App 🚀
```
Run ➡️ run_app.bat
```
## Usage
Once you have the Streamlit  web application up and running, you can perform the following steps:

1. Upload the Text File.
2. Once the Text File is loaded as the Vector Store Database it will show a success alert "Document is Loaded".
3. Insert the question in "Ask" textbox and submit your question for LLM to generate the answer.
